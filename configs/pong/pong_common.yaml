# pong_common.yaml

env: ALE/Pong-v5
render: False
num_envs: 8

atari:
  stack_size: 4

quantize: False

# network_type: cnn
# policy_type: logits
value_net_size: ALE
policy_net_size: ALE
clip_grad: 0

value_clip: 0.1
policy_clip: 0.1
value_lr: 0.001
policy_lr: 0.0003
gamma: 0.99
gae_lambda: 0.95
max_KL: 1000000     # ignore KL divergence stopping condition
entropy_coef: 0.0

noise_scheduler_kwargs:
  start_std: 0
  min_std: 0
  max_std: 0
  decay_type: 'exponential'
  l_num_steps: 150
  e_decay_rate: 0.997
  accept_threshold: -300
  slope_threshold: 0.01
  window_size: 20
  plateau_boost: 1.5
  suppress_factor: 0.85
  frozen: true

batch_size: 256
max_epochs: 4
num_episodes: 15000
max_episode_length: 5000  # do not truncate
rollout_length: 1024      # 8 * 128, 128 steps with frameskip=4 

# 200 episodes (updates) * 24000 steps per episode = 4.8M total steps
# each of the 6 environments is allowed 4k steps (rollout_length // num_envs)
# an episode is truncated early at 2.5k steps => each env can complete at least one full episode
# Each env will complete at least 1.6 episodes.