# pong_common.yaml

env: ALE/Pong-v5
render: False
num_envs: 8

atari:
  stack_size: 4

quantize: False

log_frequency: 15

# network_type: cnn
# policy_type: logits
value_net_size: ALE
policy_net_size: ALE
clip_grad: 0

value_clip: 0.1
policy_clip: 0.1
value_lr: 0.00025
policy_lr: 0.00025
gamma: 0.99
gae_lambda: 0.95
max_KL: 0           # KL divergence stopping condition turned off
entropy_coef: 0.00

batch_size: 256           # 32 * num_envs
max_epochs: 3
num_episodes: 9765        # 9765*1025 = 9999360 = ~10M steps
max_episode_length: 5000  # do not truncate
rollout_length: 1024      # 16 * 128 (num_envs=16 * Horizon=128)

# https://arxiv.org/pdf/1707.06347 Appendix A table 5